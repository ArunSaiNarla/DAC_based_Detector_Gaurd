# DAC_based_Detector_Gaurd

We are addressing two issues: first, object detection systems are inherently vulnerable to localized patch hiding attacks; second, there are insufficiently strong defences against these threats. Even though they work well in pristine settings, traditional object detectors are easily tricked by maliciously constructed data, which can result in disastrous failures in practical applications. For instance, an adversarial patch on a stop sign would make it invisible to the sensing system of an autonomous car, which might lead to serious collisions. Moreover, there is a severe weakness
in the security because most current defences are focused on image classification rather than object detection. Most of the earlier works rely on heuristic techniques that may not hold under sophisticated adversarial attacks but do not provide formal security guarantees. This work aims to fill this gap by developing a framework that ensures formal robustness against localized attacks and enhances the detection performance under adversarial settings.
